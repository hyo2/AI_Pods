"""
ì¥ë©´ ë¬˜ì‚¬ ë…¸ë“œ (LangGraph)
ì„ íƒëœ ì¥ë©´ì˜ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (Global Visual + Scene Content)
"""

import json
import re
from typing import List, Dict, Any, Optional

# Vertex AI import
try:
    import vertexai
    from vertexai.generative_models import GenerativeModel
    VERTEXAI_AVAILABLE = True
except ImportError:
    VERTEXAI_AVAILABLE = False
    print("âš ï¸  vertexai íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")


# PodcastScene import
try:
    from script_parser_node import PodcastScene
except ImportError:
    import sys
    import os
    sys.path.insert(0, os.path.dirname(__file__))
    try:
        from script_parser_node import PodcastScene
    except ImportError:
        print("âš ï¸  script_parser_nodeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        PodcastScene = None


class SceneDescriptionNode:
    """
    ì¥ë©´ ë¬˜ì‚¬ ë…¸ë“œ - ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
    
    ê¸°ëŠ¥:
    1. Global Visual Guidelines ì ìš©
    2. Scene Visual Concept ìƒì„±
    3. Final Image Prompt ì¡°í•©
    4. Composition Rules ì ìš© (í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´)
    """
    
    # ì¥ë©´ ë¬˜ì‚¬ í”„ë¡¬í”„íŠ¸
    SCENE_DESCRIPTION_PROMPT = """ë‹¹ì‹ ì€ AI ì´ë¯¸ì§€ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
Imagen, DALL-E, Midjourney ë“±ì˜ ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ì‘ì„± ê²½í—˜ì´ í’ë¶€í•©ë‹ˆë‹¤.

**ì‘ì—…:** íŒŸìºìŠ¤íŠ¸ ë¹„ë””ì˜¤ì˜ íŠ¹ì • ì¥ë©´ì„ ìœ„í•œ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.

**Global Visual Guidelines (ì „ì²´ ê·œì¹™):**
```
Art Style: {art_style}
Art Details: {art_style_details}

Color Palette:
- Primary: {color_primary}
- Secondary: {color_secondary}
- Accent: {color_accent}
- Background: {color_background}

Overall Mood: {overall_mood}
Emotional Tone: {emotional_tone}

Recurring Elements:
- Character: {recurring_character}
- Motifs: {recurring_motifs}
- Icon Style: {icon_style}

Composition Rules (ì¤‘ìš”!):
- Text Position: {text_position}
- Safe Zone: {text_safe_zone}
- Preference: {composition_preference}
- Avoid: {composition_avoid}
```

**í˜„ì¬ ì¥ë©´ ì •ë³´:**
```
ì‹œê°„: {timestamp}
ë‚´ìš©: {scene_text}
ì±•í„°: {chapter_title}
Visual Type: {visual_type}
```

**ì‘ì—… ë‹¨ê³„:**

1. **Visual Concept (ì‹œê°ì  ê°œë…):**
   ì¥ë©´ ë‚´ìš©ì„ ì‹œê°í™” ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ë¬˜ì‚¬ë¡œ ë³€í™˜í•˜ì„¸ìš”.
   
   ì˜ˆì‹œ:
   - "TTS ê¸°ìˆ  ì„¤ëª…" â†’ "Text document transforming into audio waves through TTS pipeline"
   - "ì‚¬ìš© ì‚¬ë¡€" â†’ "Business professional using laptop with AI assistant visualization"

2. **Key Elements (ì£¼ìš” ìš”ì†Œ):**
   ì´ë¯¸ì§€ì— ë°˜ë“œì‹œ í¬í•¨ë˜ì–´ì•¼ í•  ê°ì²´ë“¤ì„ ë‚˜ì—´í•˜ì„¸ìš”.
   
   ì˜ˆì‹œ: ["Document icon", "Arrow flow", "Audio waveform", "API badge"]

3. **Composition (êµ¬ë„):**
   í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„ì„ í™•ë³´í•œ êµ¬ë„ë¥¼ ì œì•ˆí•˜ì„¸ìš”.
   
   ë°˜ë“œì‹œ í¬í•¨:
   - {text_safe_zone} empty for text overlay
   - {composition_preference}

4. **Final Prompt:**
   ìœ„ ëª¨ë“  ìš”ì†Œë¥¼ ì¡°í•©í•˜ì—¬ ìµœì¢… í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•˜ì„¸ìš”.
   
   í˜•ì‹:
   ```
   [Art Style] of [Visual Concept] with [Key Elements].
   [Composition]. [Lighting/Tone].
   Color palette: [Colors].
   [Mood]. [Additional Details].
   High quality, professional.
   ```

**JSON ì‘ë‹µ:**
```json
{{
    "visual_concept": "êµ¬ì²´ì ì¸ ì‹œê°ì  ê°œë… ì„¤ëª…",
    "key_elements": ["ìš”ì†Œ1", "ìš”ì†Œ2", "ìš”ì†Œ3"],
    "composition": {{
        "layout": "êµ¬ë„ ì„¤ëª…",
        "focal_point": "ì´ˆì  ìœ„ì¹˜",
        "negative_space": "{text_safe_zone} for text overlay"
    }},
    "lighting": "ì¡°ëª… ì„¤ëª…",
    "final_prompt": "ì™„ì„±ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì˜ì–´)"
}}
```

**ì¤‘ìš” ê·œì¹™:**
- Final PromptëŠ” ë°˜ë“œì‹œ ì˜ì–´ë¡œ
- Compositionì— í…ìŠ¤íŠ¸ ê³µê°„ ë°˜ë“œì‹œ í¬í•¨
- Global Visual Guidelines ìŠ¤íƒ€ì¼ ìœ ì§€
- êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ (ì¶”ìƒì  í‘œí˜„ í”¼í•˜ê¸°)
- 150-200 ë‹¨ì–´ ì •ë„
"""

    def __init__(
        self,
        project_id: str = None,
        location: str = "us-central1",
        model_name: str = "gemini-2.5-flash"
    ):
        """ì¥ë©´ ë¬˜ì‚¬ ë…¸ë“œ ì´ˆê¸°í™”"""
        # í”„ë¡œì íŠ¸ ID ì²˜ë¦¬
        if project_id is None:
            import os
            project_id = os.getenv("GOOGLE_CLOUD_PROJECT") or os.getenv("GCP_PROJECT")
            if not project_id:
                print("âš ï¸  í”„ë¡œì íŠ¸ ID ì—†ìŒ - ë”ë¯¸ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        
        self.project_id = project_id
        self.location = location
        self.model_name = model_name
        
        # Vertex AI ì´ˆê¸°í™”
        if VERTEXAI_AVAILABLE and project_id:
            try:
                vertexai.init(project=project_id, location=location)
                self.model = GenerativeModel(model_name)
                print(f"âœ… Vertex AI ì´ˆê¸°í™” ì™„ë£Œ: {model_name}")
            except Exception as e:
                print(f"âš ï¸  Vertex AI ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                self.model = None
        else:
            self.model = None
    
    def generate_image_prompt(
        self,
        scene: PodcastScene,
        metadata: Any,  # PodcastMetadata
        chapter: Optional[Any] = None
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì¥ë©´ì˜ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        if not self.model:
            return self._dummy_prompt(scene, metadata)
        
        # Visual Guidelines ì¶”ì¶œ
        visual = metadata.visual
        
        # ì±•í„° ì°¾ê¸° (ì—†ìœ¼ë©´)
        if not chapter:
            chapter = self._find_chapter(scene, metadata.content.chapters)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.SCENE_DESCRIPTION_PROMPT.format(
            # Art Style
            art_style=visual.art_style,
            art_style_details=visual.art_style_details.get('primary', ''),
            
            # Colors
            color_primary=visual.color_palette.primary,
            color_secondary=visual.color_palette.secondary,
            color_accent=visual.color_palette.accent,
            color_background=visual.color_palette.background,
            
            # Mood
            overall_mood=visual.overall_mood,
            emotional_tone=visual.emotional_tone,
            
            # Recurring Elements
            recurring_character=visual.recurring_elements.get('character', ''),
            recurring_motifs=', '.join(visual.recurring_elements.get('motifs', [])),
            icon_style=visual.recurring_elements.get('icons_style', ''),
            
            # Composition Rules
            text_position=visual.composition_rules.text_position,
            text_safe_zone=visual.composition_rules.safe_zone,
            composition_preference=visual.composition_rules.preference,
            composition_avoid=visual.composition_rules.avoid,
            
            # Scene Info
            timestamp=scene.timestamp_start,
            scene_text=scene.text,
            chapter_title=chapter.title if chapter else "ì•Œ ìˆ˜ ì—†ìŒ",
            visual_type=getattr(scene, 'visual_type', 'concept')
        )
        
        try:
            # Gemini í˜¸ì¶œ
            response = self.model.generate_content(
                prompt,
                generation_config={
                    "temperature": 0.7,  # ì°½ì˜ì„± í•„ìš”
                    "top_p": 0.9,
                    "max_output_tokens": 1000
                }
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.text.strip()
            response_text = re.sub(r'```json\s*', '', response_text)
            response_text = re.sub(r'```\s*', '', response_text)
            
            result = json.loads(response_text)
            return result
        
        except Exception as e:
            print(f"âš ï¸  í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return self._dummy_prompt(scene, metadata)
    
    def generate_prompts_for_scenes(
        self,
        scenes: List[PodcastScene],
        metadata: Any,
        show_progress: bool = True
    ) -> List[PodcastScene]:
        """
        ì—¬ëŸ¬ ì¥ë©´ì˜ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        """
        print(f"\nğŸ¨ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")
        print("="*80)
        print(f"ì´ ì¥ë©´: {len(scenes)}ê°œ")
        
        for i, scene in enumerate(scenes):
            if show_progress:
                print(f"\n[{i+1}/{len(scenes)}] {scene.scene_id} í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘...")
                print(f"  ë‚´ìš©: {scene.text[:60]}...")
            
            # ì±•í„° ì°¾ê¸°
            chapter = self._find_chapter(scene, metadata.content.chapters)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            result = self.generate_image_prompt(scene, metadata, chapter)
            
            # Sceneì— ì €ì¥
            scene.image_title = result.get('visual_concept', '')[:200]
            scene.image_prompt = result.get('final_prompt', '')
            
            # ì¶”ê°€ ë©”íƒ€ë°ì´í„°
            if not hasattr(scene, 'image_metadata'):
                scene.__dict__['image_metadata'] = {}
            
            scene.image_metadata = {
                'visual_concept': result.get('visual_concept', ''),
                'key_elements': result.get('key_elements', []),
                'composition': result.get('composition', {}),
                'lighting': result.get('lighting', '')
            }
            
            if show_progress:
                print(f"  âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
                print(f"  ì»¨ì…‰: {scene.image_title[:80]}...")
        
        print("\n" + "="*80)
        print("âœ… í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
        print("="*80)
        
        return scenes
    
    def _find_chapter(self, scene: PodcastScene, chapters: List) -> Any:
        """ì¥ë©´ì´ ì†í•œ ì±•í„° ì°¾ê¸°"""
        scene_time = self._time_to_seconds(scene.timestamp_start)
        
        for chapter in chapters:
            start = self._time_to_seconds(chapter.start_time)
            end = self._time_to_seconds(chapter.end_time)
            
            if start <= scene_time < end:
                return chapter
        
        return None
    
    def _time_to_seconds(self, time_str: str) -> int:
        """ì‹œê°„ ë¬¸ìì—´ì„ ì´ˆë¡œ ë³€í™˜"""
        parts = time_str.split(":")
        if len(parts) == 3:
            h, m, s = map(int, parts)
            return h * 3600 + m * 60 + s
        return 0
    
    def _dummy_prompt(self, scene: PodcastScene, metadata: Any) -> Dict[str, Any]:
        """ë”ë¯¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        visual = metadata.visual
        
        # ê°„ë‹¨í•œ ì»¨ì…‰ ìƒì„±
        concept = f"Illustration representing: {scene.text[:100]}"
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸
        final_prompt = f"""{visual.art_style} of an abstract concept visualization.
{visual.composition_rules.preference}.
{visual.composition_rules.safe_zone} empty for text overlay.
Color palette: {visual.color_palette.primary}, {visual.color_palette.secondary}.
{visual.overall_mood}.
High quality, professional, clean design."""
        
        return {
            'visual_concept': concept,
            'key_elements': ['Abstract shapes', 'Data visualization', 'Clean design'],
            'composition': {
                'layout': 'Top-weighted',
                'focal_point': 'Upper two-thirds',
                'negative_space': visual.composition_rules.safe_zone
            },
            'lighting': 'Bright, even lighting',
            'final_prompt': final_prompt
        }
    
    def __call__(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """
        LangGraph ë…¸ë“œë¡œ ì‹¤í–‰
        """
        selected_scenes = state.get("selected_scenes", [])
        metadata = state.get("metadata")
        
        if not selected_scenes or not metadata:
            print("âš ï¸  ì„ íƒëœ ì¥ë©´ì´ë‚˜ ë©”íƒ€ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {**state}
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        scenes_with_prompts = self.generate_prompts_for_scenes(
            selected_scenes,
            metadata
        )
        
        return {
            **state,
            "scenes_with_prompts": scenes_with_prompts
        }


# ============================================================================
# í—¬í¼ í•¨ìˆ˜ë“¤
# ============================================================================

def print_prompts_summary(scenes: List[PodcastScene]):
    """ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "="*80)
    print("ğŸ“‹ ìƒì„±ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ëª©ë¡")
    print("="*80)
    
    for i, scene in enumerate(scenes, 1):
        print(f"\n{i}. {scene.scene_id} [{scene.timestamp_start}]")
        print(f"   ì»¨ì…‰: {scene.image_title}")
        print(f"   í”„ë¡¬í”„íŠ¸:")
        print(f"   {scene.image_prompt}")
        print()


def export_prompts(scenes: List[PodcastScene], output_path: str):
    """í”„ë¡¬í”„íŠ¸ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    data = []
    
    for scene in scenes:
        data.append({
            'scene_id': scene.scene_id,
            'timestamp': scene.timestamp_start,
            'duration': scene.duration,
            'text': scene.text,
            'image_title': scene.image_title,
            'image_prompt': scene.image_prompt,
            'image_metadata': getattr(scene, 'image_metadata', {})
        })
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í”„ë¡¬í”„íŠ¸ ì €ì¥: {output_path}")


if __name__ == "__main__":
    print("Scene Description Node - ì¥ë©´ ë¬˜ì‚¬ ë…¸ë“œ")
    print("Importí•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”: from scene_description_node import SceneDescriptionNode")
