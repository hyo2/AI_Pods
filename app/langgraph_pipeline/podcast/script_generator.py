# app/langgraph_pipeline/podcast/script_generator.py

import json
import os
import re
import logging
from google.oauth2 import service_account
from vertexai.generative_models import GenerativeModel
import vertexai

# [Supabase] ÌîÑÎ°úÏ†ùÌä∏Ïùò Supabase ÏÑúÎπÑÏä§ ÌååÏùº Í≤ΩÎ°úÏóê ÎßûÏ∂∞ ÏàòÏ†ïÌïòÏÑ∏Ïöî.
from app.services.supabase_service import supabase 
from .prompt_service import PromptTemplateService

logger = logging.getLogger(__name__)


def _extract_json_from_llm(text: str) -> dict:
    """
    LLM Ï∂úÎ†•ÏóêÏÑú JSONÎßå ÏïàÏ†ÑÌïòÍ≤å Ï∂îÏ∂ú
    - ```json ÏΩîÎìúÎ∏îÎ°ù Ï†úÍ±∞
    - Í∞ÄÏû• Î∞îÍπ• {} Î∏îÎ°ù Ï∂îÏ∂ú
    """
    # ÏΩîÎìúÎ∏îÎ°ù Ï†úÍ±∞
    cleaned = re.sub(r"```json|```", "", text, flags=re.IGNORECASE).strip()

    # Í∞ÄÏû• Î∞îÍπ• JSON Î∏îÎ°ù Ï∞æÍ∏∞
    match = re.search(r"\{.*\}", cleaned, re.DOTALL)
    if not match:
        raise ValueError("LLM Ï∂úÎ†•ÏóêÏÑú JSON Î∏îÎ°ùÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏùå")

    json_text = match.group().strip()

    # üî• Ï∂îÍ∞Ä: Í∞úÌñâ Í∞ïÏ†ú escape
    json_text = json_text.replace("\n", "\\n")
    
    return json.loads(json_text)


class ScriptGenerator:
    """LLMÏùÑ ÏÇ¨Ïö©Ìïú ÌåüÏ∫êÏä§Ìä∏ Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ± (Supabase + Vertex AI)"""
    
    def __init__(self, project_id: str, region: str, sa_file: str, style: str = "explain"):
        self.project_id = project_id
        self.region = region
        self.sa_file = sa_file
        self.style = style
        
        # Ï¥àÍ∏∞Ìôî Ïã§Ìñâ
        self._init_vertex_ai()
        self._load_prompt_template()
    
    def _init_vertex_ai(self):
        """Vertex AI Ï¥àÍ∏∞Ìôî"""
        
        # [Ï§ëÏöî] 401 Ïù∏Ï¶ù Ïò§Î•ò Î∞©ÏßÄÎ•º ÏúÑÌïú ÌôòÍ≤Ω Î≥ÄÏàò Í∞ïÏ†ú ÏÑ§Ï†ï
        if self.sa_file and os.path.exists(self.sa_file):
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = self.sa_file
            logger.info(f"Ïù∏Ï¶ù ÌååÏùº ÌôòÍ≤ΩÎ≥ÄÏàò ÏÑ§Ï†ï ÏôÑÎ£å: {self.sa_file}")

        credentials = self._load_credentials()
        
        vertexai.init(
            project=self.project_id, 
            location=self.region, 
            credentials=credentials
        )
        logger.info(f"Vertex AI Ï¥àÍ∏∞Ìôî ÏôÑÎ£å: {self.project_id} / {self.region}")
    
    def _load_credentials(self):
        """ÏÑúÎπÑÏä§ Í≥ÑÏ†ï Ïù∏Ï¶ù Ï†ïÎ≥¥ Î°úÎìú"""
        if os.path.exists(self.sa_file):
            try:
                return service_account.Credentials.from_service_account_file(self.sa_file)
            except Exception as e:
                raise RuntimeError(f"ÏÑúÎπÑÏä§ Í≥ÑÏ†ï ÌååÏùº Î°úÎìú Ïò§Î•ò: {e}")
        else:
            logger.warning(f"ÏÑúÎπÑÏä§ Í≥ÑÏ†ï ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {self.sa_file}")
            return None
    
    def _load_prompt_template(self):
        """ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø Î°úÎìú (Supabase Ïó∞Îèô)"""
        try:
            # Supabase ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏Î•º Ï†ÑÎã¨ÌïòÏó¨ ÌÖúÌîåÎ¶ø Ï°∞Ìöå
            template = PromptTemplateService.get_template(supabase, self.style)
            
            if template:
                self.system_prompt = template["system_prompt"]
                self.user_prompt_template = template["user_prompt_template"]
                logger.info(f"ÌîÑÎ°¨ÌîÑÌä∏ ÌÖúÌîåÎ¶ø Î°úÎìú ÏÑ±Í≥µ: {template['style_name']}")
            else:
                logger.warning(f"ÌÖúÌîåÎ¶øÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏñ¥ Í∏∞Î≥∏ ÌÖúÌîåÎ¶ø ÏÇ¨Ïö©: {self.style}")
                # Í∏∞Î≥∏ ÌÖúÌîåÎ¶ø Ìè¥Î∞±
                default_template = PromptTemplateService.get_default_template(supabase)
                self.system_prompt = default_template["system_prompt"]
                self.user_prompt_template = default_template["user_prompt_template"]
                
        except Exception as e:
            logger.error(f"ÌÖúÌîåÎ¶ø Î°úÎìú Ï§ë Ïò§Î•ò Î∞úÏÉù: {e}")
            # ÏµúÌõÑÏùò ÏàòÎã®: ÌïòÎìúÏΩîÎî© Ìè¥Î∞±
            self.system_prompt = "You are a teacher. Respond in Korean."
            self.user_prompt_template = "Create a dialogue in Korean:\n{combined_text}"

    def generate_script(
        self, 
        combined_text: str, 
        host_name: str, 
        guest_name: str,
        duration: int = 5,           # Í∏∞Î≥∏Í∞í 5Î∂Ñ
        user_prompt: str = ""        # ÏÇ¨Ïö©Ïûê Ï∂îÍ∞Ä ÏöîÏ≤≠
    ) -> str:
        """ÌåüÏ∫êÏä§Ìä∏ Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ±"""
        # ÌôòÍ≤Ω Î≥ÄÏàòÏóêÏÑú Î™®Îç∏Î™Ö Í∞ÄÏ†∏Ïò§Í∏∞
        model_name = os.getenv("VERTEX_AI_MODEL_TEXT", "gemini-2.0-flash-exp")
        
        logger.info(f"Î™®Îç∏ ÏÇ¨Ïö©: {model_name} / Î™©Ìëú ÏãúÍ∞Ñ: {duration}Î∂Ñ")
        
        # ÏãúÏä§ÌÖú ÌîÑÎ°¨ÌîÑÌä∏ÏôÄ Ìï®Íªò Î™®Îç∏ ÏÉùÏÑ±
        model = GenerativeModel(
            model_name,
            system_instruction=self.system_prompt 
        )
        
        # ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ± (ÏãúÍ∞Ñ + ÏÇ¨Ïö©Ïûê ÏöîÏ≤≠ + Ï£º/Î≥¥Ï°∞ ÏÜåÏä§ ÏßÄÏπ® Ìè¨Ìï®)
        final_prompt = self._create_prompt(combined_text, host_name, guest_name, duration, user_prompt)
        
        config = {
            "max_output_tokens": 8192,
            "temperature": 0.7,
        }
        
        try:
            logger.info("LLM Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ± ÏöîÏ≤≠ Ï§ë...")
            response = model.generate_content(final_prompt, generation_config=config)
            raw_text = getattr(response, "text", "")
            
            if not raw_text:
                raise RuntimeError("Î™®Îç∏Ïù¥ ÌÖçÏä§Ìä∏Î•º Î∞òÌôòÌïòÏßÄ ÏïäÏïòÏäµÎãàÎã§")
            
            
            # JSON ÌååÏã±
            try:
                data = _extract_json_from_llm(raw_text)
                title = data["title"].strip()
                script_text = data["script"].strip()
            except Exception as e:
                logger.error(f"JSON ÌååÏã± Ïã§Ìå®. ÏõêÎ≥∏ Ï∂úÎ†• ÎØ∏Î¶¨Î≥¥Í∏∞:\n{raw_text[:500]}")

                # üî• fallback: JSON Ïã§Ìå® Ïãú ÏÉùÏÑ± title, Ïä§ÌÅ¨Î¶ΩÌä∏ÎùºÎèÑ ÏÇ¥Î¶º
                title_match = re.search(r'"title"\s*:\s*"([^"]+)"', raw_text)
                title = title_match.group(1) if title_match else "ÏÉà ÌåüÏ∫êÏä§Ìä∏"
                script_text = raw_text.strip()

                logger.warning("JSON ÌååÏã± Ïã§Ìå® ‚Üí raw_textÎ•º Ïä§ÌÅ¨Î¶ΩÌä∏Î°ú ÏÇ¨Ïö©Ìï©ÎãàÎã§.")


            # Ïä§ÌÅ¨Î¶ΩÌä∏ ÌõÑÏ≤òÎ¶¨
            script_text = self._clean_script(script_text)

            logger.info(f"Ï†úÎ™© ÏÉùÏÑ± ÏôÑÎ£å: {title}")
            logger.info(f"Ïä§ÌÅ¨Î¶ΩÌä∏ Í∏∏Ïù¥: {len(script_text)}Ïûê")

            logger.info(f"Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ± ÏôÑÎ£å (Ïä§ÌÉÄÏùº: {self.style}, Í∏∏Ïù¥: {len(script_text)}Ïûê)")

            return {
                "title": title,
                "script": script_text.strip()
            }
            
        except Exception as e:
            logger.error(f"Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ± Ïò§Î•ò: {e}", exc_info=True)
            raise RuntimeError(f"Ïä§ÌÅ¨Î¶ΩÌä∏ ÏÉùÏÑ± Ïã§Ìå®: {str(e)}") from e
    
    def _create_prompt(self, combined_text: str, host_name: str, guest_name: str, duration: int, user_prompt: str = "") -> str:
        """ÌÖúÌîåÎ¶øÏùÑ ÏÇ¨Ïö©Ìï¥ ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±"""
        
        # 1. ÏÜåÏä§ ÌÖçÏä§Ìä∏ Í∏∏Ïù¥ Ï†úÌïú (6ÎßåÏûêÎ°ú ÏÉÅÌñ•)
        max_text_length = 60000
        if len(combined_text) > max_text_length:
            logger.warning(f"ÌÖçÏä§Ìä∏Í∞Ä ÎÑàÎ¨¥ ÍπÅÎãàÎã§ ({len(combined_text)}Ïûê). {max_text_length}ÏûêÎ°ú Ï†úÌïúÌï©ÎãàÎã§.")
            combined_text = combined_text[:max_text_length] + "\n\n[... truncated ...]"
        
        # 2. ÏãúÍ∞Ñ(Î∂Ñ) Í∏∞Î∞ò Í∏ÄÏûê Ïàò Í≥ÑÏÇ∞
        chars_per_min = 500
        target_chars = duration * chars_per_min
        
        # 3. [ÌïµÏã¨ ÏàòÏ†ï] ÏßÄÏãúÏÇ¨Ìï≠ ÏÉùÏÑ± (Ï£º/Î≥¥Ï°∞ ÏÜåÏä§ Ï≤òÎ¶¨ Î∞©Î≤ï Ìè¨Ìï®)
        instruction_block = (
            f"First, generate a concise and engaging TITLE for this podcast.\n"
            f"Then, write a script suitable for a **{duration}-minute conversation/lecture**.\n"
            f"\n"
            f"OUTPUT FORMAT (IMPORTANT):\n"
            f"Respond strictly in valid JSON format as follows:\n"
            f"{{\n"
            f'  "title": "ÌåüÏ∫êÏä§Ìä∏ Ï†úÎ™©",\n'
            f'  "script": "Ï†ÑÏ≤¥ ÌåüÏ∫êÏä§Ìä∏ Ïä§ÌÅ¨Î¶ΩÌä∏"\n'
            f"}}\n"
            f"\n"
            f"IMPORTANT RULES:\n"
            f"- Output ONLY valid JSON.\n"
            f"- Do NOT include explanations, markdown, or code blocks.\n"
            f"- Do NOT include any text before or after the JSON.\n"
            f"Script requirements:\n"
            f"   - Target length: Approximately **{target_chars} Korean characters**.\n"
            f"   - **Source Handling Instructions:**\n"
            f"     The text below is divided into '[MAIN SOURCE]' and '[AUXILIARY SOURCE]'.\n"
            f"     1. **[MAIN SOURCE]:** This is the CORE topic. Dedicate 80-90% of the script to explaining this content.\n"
            f"     2. **[AUXILIARY SOURCE]:** Use this ONLY for supporting details, definitions, examples, or context. Do not make it the main topic.\n"
        )

        # 4. ÏÇ¨Ïö©Ïûê Ï∂îÍ∞Ä ÏöîÏ≤≠ Î∞òÏòÅ
        if user_prompt and user_prompt.strip():
            instruction_block += f"\n   - **USER SPECIAL REQUEST:** {user_prompt}\n"
            instruction_block += f"   (Please reflect the user's request above explicitly in the script tone or content.)"
        
        return self.user_prompt_template.format(
            combined_text=combined_text,
            host_name=host_name,
            guest_name=guest_name,
            length_instruction=instruction_block
        )
    
    def _clean_script(self, script_text: str) -> str:
        """Ïä§ÌÅ¨Î¶ΩÌä∏ ÌÖçÏä§Ìä∏ Ï†ïÎ¶¨"""
        script_text = re.sub(
            r"```python|```json|```text|```|```markdown", 
            "", 
            script_text, 
            flags=re.IGNORECASE
        )
        script_text = re.sub(r"[\*\U00010000-\U0010ffff]|#", "", script_text)
        script_text = re.sub(r'\n{3,}', '\n\n', script_text)
        return script_text.strip()