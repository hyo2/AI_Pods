[00:00:00] [진행자]: 안녕하세요, 청취자 여러분!깊이 있는 기술 이야기와 그 속에 담긴 개발자들의 뜨거운 열정을 들어보는 시간, 꿈 많은 사람의 이야기 팟캐스트 진행자입니다.오늘은 특별한 손님과 함께 인공지능, 특히 LLM거대 언어 모델 에이전트 개발의 복잡한 여정과 그 해답을 찾아가는 이야기를 나눠보려 합니다.
[00:00:23] [진행자]: 꿈 많은 사람의 이야기라는 블로그를 운영하며 깊이 있는 기술 포스팅으로 많은 개발자들에게 영감을 주고 계신 이수진님을 모셨습니다.이수진님, 안녕하세요!
[00:00:35] [게스트]: 안녕하세요, 이수진입니다. 오늘 이렇게 귀한 자리에 초대해 주셔서 감사합니다. 제 이야기를 나눌 수 있게 되어 기쁩니다.
[00:00:44] [진행자]: 이수진님 블로그의 이름이 꿈 많은 사람의 이야기인데, 이 이름처럼 AI 분야에서 어떤 꿈을 꾸고 계신지, 그리고 특히 LLM 에이전트 개발에 관심을 갖게 된 계기가 궁금합니다. 많은 분들이 LLM의 잠재력에 열광하지만, 실제 애플리케이션 개발은 쉽지 않거든요.
[00:01:05] [게스트]: 네, 저는 AI가 단순히 정보를 처리하는 도구를 넘어, 인간의 의도를 이해하고 능동적으로 문제를 해결하는 파트너가 될 수 있다고 믿습니다.특히 LLM의 등장으로 이런 꿈이 현실에 한 발짝 더 다가왔다고 생각했죠.
[00:01:23] [게스트]: 처음에는 LLM의 잠재력에 매료되었지만, 막상 실제 애플리케이션을 만들려고 하니, 단순히 LLM을 한 번 호출하는 것만으로는 부족하다는 걸 깨달았습니다.마치 천재적인 두뇌를 가진 아이에게 이거 해 하고 명령만 내리는 느낌이랄까요.
[00:01:42] [게스트]: 더 복잡한 상황에서는 이걸 해보고 안 되면 저걸 해봐, 이 정보가 부족하면 다시 물어봐 같은 지능적인 흐름 제어가 필요했습니다.이 지점에서 LLM 에이전트의 필요성을 절감하게 됐습니다.
[00:01:56] [진행자]: 그렇다면, 기존의 방식, 예를 들어 LangChain의 단순한 체인 구조로는 어떤 한계에 부딪히셨나요? 구체적인 어려움이 있었다면요? 많은 분들이 비슷한 고민을 하고 계실 것 같습니다.
[00:02:11] [게스트]: 네, 가장 큰 문제는 순환이 어렵다는 점이었습니다.예를 들어, 사용자로부터 특정 정보가 부족해서 다시 질문해야 할 때, 혹은 특정 조건이 만족될 때까지 어떤 작업을 반복해야 할 때, 단순한 체인 구조로는 이런 돌고 도는 로직을 구현하기가 굉장히 까다로웠습니다.
[00:02:32] [게스트]: 코드가 복잡해지고 유지보수가 어려워지는 건 물론이고, 에이전트가 정말 지능적으로 행동한다는 느낌을 주기가 힘들었죠.마치 정해진 길만 가는 기차 같았다고 할까요?정해진 순서대로만 움직이는 기차로는 복잡한 도시를 탐험할 수 없듯이, 저 역시 더 유연하고 동적인 에이전트를 만들고 싶다는 갈증이 있었습니다.
[00:02:54] [게스트]: 그러다 우연히 LangGraph를 접하게 되었고, 이 라이브러리가 제가 찾던 해답이라는 직감을 받았습니다.
[00:03:02] [진행자]: LangGraph가 그 갈증을 해소해 주었다고 말씀하셨는데, 어떤 점에서 그렇게 느끼셨는지, 그리고 LangGraph의 핵심 개념인 그래프 형태의 제어가 왜 그렇게 강력한지 이수진님만의 통찰을 듣고 싶습니다.
[00:03:18] [게스트]: LangGraph는 LLM 애플리케이션의 뇌를 설계하는 도구라고 생각합니다.기존 체인이 일직선 도로라면, LangGraph는 복잡한 교차로와 우회도로까지 설계할 수 있는 도시 계획과 같아요.특히 상태State, 노드Node, 엣지Edge라는 세 가지 핵심 요소가 이 복잡성을 단순화시켜 주었습니다.
[00:03:41] [게스트]: 마치 프로그램의 기억, 행동, 흐름을 명확하게 분리해서 설계할 수 있게 된 거죠.노드는 LLM 호출이나 외부 도구 사용 같은 개별 행동을 정의하고, 엣지는 이 행동들 사이의 흐름을 결정합니다.그리고 이 모든 과정에서 상태가 에이전트의 기억을 유지하며 맥락을 이어가게 합니다.
[00:04:04] [게스트]: 이 구조 덕분에 사용자에게 다시 질문하기, 특정 조건이 충족될 때까지 반복하기 같은 복잡한 로직을 마치 블록을 쌓듯이 쉽게 구현할 수 있게 된 겁니다.이 유연성이야말로 LangGraph의 가장 큰 매력이라고 생각합니다.
[00:04:22] [진행자]: 그 세 가지 핵심 요소 중 이수진님께서 가장 중요하다고 생각하시거나, 혹은 설계 단계에서 가장 많은 고민을 했던 부분은 무엇인가요? 특히 상태는 에이전트의 기억과 직결되는데, 이를 어떻게 설계해야 효과적일지 궁금합니다. 이 부분에서 많은 시행착오를 겪었을 것 같습니다.
[00:04:44] [게스트]: 음, 세 가지 모두 중요하지만, 저는 상태State 설계에 가장 많은 공을 들였습니다.왜냐하면 에이전트의 지능이 얼마나 오래, 그리고 얼마나 정확하게 맥락을 유지하느냐가 바로 이 상태에 달려있기 때문입니다.
[00:05:01] [게스트]: 처음에는 단순히 메시지 리스트만 넣을까도 생각했지만, 대화 턴 수라든지, 사용자의 특정 선호도, 혹은 외부 API 호출 결과 같은 부가 정보들을 함께 관리해야 에이전트가 더 풍부하고 유연하게 반응할 수 있다는 것을 깨달았죠.
[00:05:18] [게스트]: Python의 TypedDict를 사용해서 상태의 구조를 명확하게 정의하는 것이 나중에 확장성을 고려했을 때 정말 큰 도움이 되었습니다.마치 사람의 단기 기억과 장기 기억을 어떻게 구성할지 고민하는 과정과 비슷했습니다.어떤 정보가 필요하고, 어떤 정보는 버려도 되는지, 그리고 어떤 방식으로 저장해야 효율적일지 끊임없이 고민했습니다.
[00:05:43] [진행자]: 블로그에서 vLLM과 Qwen3 모델을 활용한 챗봇 예제를 보여주셨습니다. 이 예제를 통해 LangGraph의 작동 방식을 설명해 주셨는데, 특히 ChatOpenAI 클래스를 사용하면서 실제로는 vLLM 서버에 연동하신 부분이 인상 깊었습니다. 이러한 접근 방식을 선택하신 특별한 이유나, 구현 과정에서 겪었던 흥미로운 점이 있으신가요?
[00:06:07] [게스트]: 네, 이 부분은 실용적인 측면을 많이 고려했습니다.ChatOpenAI 인터페이스가 LLM과 상호작용하는 데 워낙 편리하고 표준화되어 있기 때문에, 이 장점을 활용하되 실제 모델은 제가 제어할 수 있는 환경에서 구동하고 싶었습니다.vLLM은 고성능 추론을 가능하게 해주고요.
[00:06:27] [게스트]: Qwen3 모델은 한국어 성능이 뛰어나고, thinking 모드나 tool 사용 같은 고급 기능을 지원해서 에이전트 개발에 매우 적합하다고 판단했습니다.이 조합을 통해 오픈AI의 강력한 API 호환성을 유지하면서도, 비용 효율적이고, 제가 원하는 모델을 자유롭게 실험할 수 있는 환경을 구축할 수 있었죠.
[00:06:50] [게스트]: 처음에는 openaiapibase 설정을 찾느라 조금 헤매기도 했지만, 한번 설정하고 나니 마치 마법처럼 작동해서 매우 만족스러웠습니다.원하는 대로 LLM을 바꿔가며 테스트할 수 있다는 점이 정말 큰 장점이었습니다.
[00:07:07] [진행자]: 예제 코드에서 messages 리스트에 Annotated와 람다 함수 lambda x, y x  y를 사용하여 새로운 메시지가 자동으로 추가되도록 하신 부분이 있습니다. 사소해 보일 수 있지만, 이런 디테일이 개발 생산성에 큰 영향을 미치기도 하는데요. 이 부분을 적용하시면서 어떤 이점을 느끼셨나요?
[00:07:32] [게스트]: 맞습니다.사소한 부분일 수 있지만, 개발자 입장에서는 이런 편리함이 정말 중요합니다.Annotated와 람다 함수를 활용한 메시지 축적 방식은 LangGraph가 상태를 자동으로 업데이트하는 메커니즘을 보여주는 좋은 예시입니다.
[00:07:49] [게스트]: 매번 직접 리스트에 append하거나 병합하는 코드를 작성할 필요 없이, LangGraph 프레임워크가 알아서 처리해주니 코드가 훨씬 간결해지고 가독성이 높아집니다.덕분에 핵심 로직, 즉 에이전트의 행동 자체에 더 집중할 수 있게 되죠.이런 프레임워크 수준의 지원이 개발 속도와 코드 품질을 동시에 높여준다고 생각합니다.
[00:08:13] [게스트]: 작은 부분이지만, 개발자의 피로도를 줄여주고 더 중요한 문제에 집중할 수 있도록 돕는다는 점에서 매우 만족스러웠습니다.
[00:08:23] [진행자]: 이번 포스팅에서는 기본적인 LangGraph 활용법을 다루셨지만, 다음번에는 조건부 엣지Conditional Edge나 여러 도구Tool를 활용하는 더 발전된 에이전트를 만들어 보겠다고 예고하셨습니다.
[00:08:37] [진행자]: 앞으로 LangGraph를 통해 어떤 종류의 AI 에이전트를 구현하고 싶으신지, 그리고 궁극적으로 AI 에이전트가 우리 삶에 어떤 긍정적인 변화를 가져올 것이라고 기대하시는지 이수진님의 비전을 듣고 싶습니다.
[00:08:53] [게스트]: LangGraph의 진정한 힘은 조건부 엣지와 도구 활용에서 나온다고 생각합니다.단순히 대화만 하는 챗봇을 넘어, 특정 조건에 따라 동적으로 판단하고, 외부 시스템과 연동하여 실제 행동을 수행하는 에이전트를 만들고 싶습니다.
[00:09:10] [게스트]: 예를 들어, 사용자의 요청을 분석해서 필요한 정보를 검색하거나, 특정 작업을 자동화하거나, 심지어는 사용자의 감정을 파악해서 적절한 반응을 보이는, 정말 살아있는 듯한 에이전트를 구현하는 것이 목표입니다.궁극적으로는 AI 에이전트가 단순한 도구를 넘어, 우리의 일상과 업무에서 든든한 파트너가 될 수 있다고 믿습니다.
[00:09:36] [게스트]: 복잡한 문제를 해결하는 데 도움을 주고, 창의적인 영감을 주며, 반복적인 작업을 대신해 인간이 더 가치 있는 일에 집중할 수 있도록 돕는 것이죠.제 블로그 이름처럼, 저는 AI가 인간의 꿈을 현실로 만드는 데 핵심적인 역할을 할 것이라고 확신합니다.
[00:09:54] [게스트]: 에이전트들이 각자의 전문 분야에서 인간을 보조하고, 협력하며, 우리의 삶을 더욱 풍요롭게 만들 것이라는 꿈을 꾸고 있습니다.
[00:10:05] [진행자]: 네, 이수진님의 깊이 있는 통찰과 비전 덕분에 LLM 에이전트와 LangGraph에 대해 훨씬 더 풍부하게 이해할 수 있었습니다. 꿈 많은 사람의 이야기라는 블로그 이름처럼, 이수진님의 앞으로의 행보와 AI가 만들어낼 미래에 큰 기대를 걸어봅니다. 오늘 귀한 시간 내주셔서 정말 감사합니다.
[00:10:28] [게스트]: 저의 이야기를 나눌 수 있는 소중한 기회를 주셔서 감사합니다. 앞으로도 꾸준히 새로운 시도들을 블로그를 통해 공유하며, 많은 분들과 함께 AI의 미래를 그려나가고 싶습니다.
[00:10:42] [진행자]: 꿈 많은 사람의 이야기 팟캐스트는 다음 시간에도 흥미로운 이야기로 찾아뵙겠습니다. 감사합니다!